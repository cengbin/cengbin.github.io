import{_ as l,o as i,c as e,O as t}from"./chunks/framework.d9e2f5d0.js";const u=JSON.parse('{"title":"大文件上传总结","description":"","frontmatter":{},"headers":[],"relativePath":"frontend/技术 之 大文件上传/README.md","filePath":"frontend/技术 之 大文件上传/README.md"}'),r={name:"frontend/技术 之 大文件上传/README.md"};function o(n,a,s,h,d,p){return i(),e("div",null,a[0]||(a[0]=[t('<h1 id="大文件上传总结" tabindex="-1">大文件上传总结 <a class="header-anchor" href="#大文件上传总结" aria-label="Permalink to &quot;大文件上传总结&quot;">​</a></h1><h2 id="背景-s" tabindex="-1">背景（S） <a class="header-anchor" href="#背景-s" aria-label="Permalink to &quot;背景（S）&quot;">​</a></h2><p>当上传一个 2GB 大小的视频文件的时候，如果直接使用 axios.post 上传，那么中途一旦出现网络卡顿，就需要重新上传这个视频文件，这就会对用户的体验造成不好的影响，有没有更好的办法解决呢？</p><h2 id="任务-t" tabindex="-1">任务（T） <a class="header-anchor" href="#任务-t" aria-label="Permalink to &quot;任务（T）&quot;">​</a></h2><p>在这种数据量极大的场景下，我们需要采用断点续传的解决方案。前端文件切片，异步上传切片文件，服务端接收临时切片文件，当最后一个切片文件上传完成后，合并所有的临时文件生成最终文件。</p><h2 id="行动-a" tabindex="-1">行动（A） <a class="header-anchor" href="#行动-a" aria-label="Permalink to &quot;行动（A）&quot;">​</a></h2><p><strong>前端</strong></p><ol><li>获取文件的hash（注意：在Web Worker线程中生成hash）</li><li>根据当前文件hash判断文件是否上传过 <ul><li>上传过则直接返回文件url</li><li>反之则继续分片上传</li></ul></li><li>初始化分片上传，获取文件的uploadId</li><li>通过uploadId获取已上传的分片</li><li>剔除掉已上传的分片数据，生成上传异步队列</li><li>异步队列分片上传（注意：Chorme浏览器限制同一域名同时最多6个HTTP链接）</li><li>完成分片上传</li><li>获取文件地址</li></ol><p><strong>后端</strong></p><ol><li>把上传的分片数据按命名规范写入.tem临时文件</li><li>读取.tmp临时分片文件数据，写入最终文件</li><li>所有分片文件上传完毕，删除.tmp临时分片文件</li></ol><h2 id="结果-r" tabindex="-1">结果（R） <a class="header-anchor" href="#结果-r" aria-label="Permalink to &quot;结果（R）&quot;">​</a></h2><ul><li>结果：解决了在大文件上传过程中产生的一些不好的用户体验。</li><li>数据：优化了大文件上传的技术，减少了服务端的流量和压力，相同文件二次上传可以实现大文件秒传。</li><li>技术：从可复用性的角度来说，可以把前后端技术封装起来，对外提供服务，以后有大文件上传需求的地方都可用。</li><li>成长：掌握了大文件上传的技术实现，以及在实现过程中应该注意的细节点。</li></ul>',12)]))}const m=l(r,[["render",o]]);export{u as __pageData,m as default};
